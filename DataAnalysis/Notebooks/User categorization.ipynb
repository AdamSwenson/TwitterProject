{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is dedicated to determining which users are pain patients and which conditions they have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:04:21.091761Z",
     "start_time": "2018-07-26T01:04:21.081303Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Plotting \n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:04:21.474386Z",
     "start_time": "2018-07-26T01:04:21.469044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:twitterproject) -> /Users/adam/Dropbox/PainNarrativesLab/TwitterProject\n",
      "/Users/adam/Dropbox/PainNarrativesLab/TwitterProject\n"
     ]
    }
   ],
   "source": [
    "%cd twitterproject\n",
    "\n",
    "# inject config value (on command line would've been --config=data-analysis)\n",
    "import sys\n",
    "sys.argv = ['data-analysis']\n",
    "import environment\n",
    "\n",
    "from TwitterDatabase.Repositories import DataRepositories as DR\n",
    "from TwitterDatabase.DatabaseAccessObjects import DataConnections as DC\n",
    "from TwitterDatabase.Models.WordORM import Word\n",
    "from TwitterDatabase.Models.TweetORM import Users as User\n",
    "from TwitterDatabase.Models.TweetORM import Tweet\n",
    "from DataAnalysis.SearchTools.WordMaps import get_adjacent_word_counts, get_adjacent_words, get_user_ids_for_word\n",
    "\n",
    "EXP_TERMS_FILEPATH = '%s/experimental-terms.xlsx' % environment.EXPERIMENTS_FOLDER\n",
    "IDS_FILEPATH = \"%s/temp_output/user-ids.xlsx\" % environment.LOG_FOLDER_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find users whose profile contains an experimental term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_rows_for_terms(wordFrame, experimentalTerms):\n",
    "    return wordFrame[wordFrame.term.isin(experimentalTerms)]\n",
    "\n",
    "\n",
    "def find_mapping(term, termMap):\n",
    "    for t in termMap.T.index:\n",
    "        if termMap[t].str.contains(term).any():\n",
    "            return t\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in terms to search for\n",
    "experimentalTerms = pd.read_excel(EXP_TERMS_FILEPATH, sheet_name='terms', squeeze=True)\n",
    "termMap = pd.read_excel(EXP_TERMS_FILEPATH, sheet_name='mapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# iterate through each of the experimental terms, \n",
    "# getting user ids for each.\n",
    "\n",
    "ids = []\n",
    "for t in termMap.T.index:\n",
    "    print(t)\n",
    "    users = []\n",
    "    for subterm in termMap[t]:\n",
    "        users += [x[0] for x in get_user_ids_for_word(subterm)]\n",
    "    users = list(set(users))\n",
    "    ids.append(pd.Series(users, name=t))\n",
    "    \n",
    "ids = pd.DataFrame(ids)\n",
    "\n",
    "# Save results\n",
    "ids.T.to_excel(IDS_FILEPATH) \n",
    "\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts of tweets belonging to users and broken out by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id1 = 10712602\n",
    "test_user_id2 = 7609402\n",
    "test_tweet_id = 340493586317582340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T21:30:46.144627Z",
     "start_time": "2018-06-05T21:30:46.140511Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tweet_count(userId):\n",
    "    \"\"\"Returns how many tweets we have for the given user id\"\"\"\n",
    "    return dao.session.query(Tweet).filter(Tweet.userID == userId).count()\n",
    "\n",
    "def get_tweets(userId):\n",
    "    \"\"\"Returns all tweets belonging to the user\"\"\"\n",
    "    return dao.session.query(Tweet).filter(Tweet.userID == userId).all()\n",
    "\n",
    "def get_tweet_timestamps(userId):\n",
    "    \"\"\"Returns the `created_at` field` for all tweets belonging to the given user \"\"\"\n",
    "    return [x.created_at for x in get_tweets(userId)]\n",
    "\n",
    "def get_user(userId):\n",
    "    \"\"\"Returns the user object for the id\"\"\"\n",
    "    return dao.session.query(User).filter(User.userID == userId).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T17:46:29.547436Z",
     "start_time": "2018-06-19T17:46:29.505996Z"
    }
   },
   "outputs": [],
   "source": [
    "e = DC.initialize_engine('mysql')\n",
    "dao = DC.DAO(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T21:30:49.207880Z",
     "start_time": "2018-06-05T21:30:48.922319Z"
    }
   },
   "outputs": [],
   "source": [
    "# load userids from file\n",
    "userIds = pd.read_excel(IDS_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T21:30:49.560069Z",
     "start_time": "2018-06-05T21:30:49.547099Z"
    }
   },
   "outputs": [],
   "source": [
    "# display counts for each condition\n",
    "print(\"Number of user descriptions containing the term \\n\")\n",
    "for r in userIds.columns:\n",
    "    print(\" %s: %s\" % (r, len(userIds[r].dropna())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tweet counts for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T21:31:24.040286Z",
     "start_time": "2018-06-05T21:30:53.724673Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = {}\n",
    "\n",
    "for condition in userIds.columns:\n",
    "    counts[condition] = []\n",
    "    for user_id in userIds[condition].dropna():\n",
    "        # look up the number of tweets that we've captured\n",
    "        # by the user.\n",
    "        r = (user_id, get_tweet_count(user_id))\n",
    "        counts[condition].append(r) \n",
    "\n",
    "# yes, we're cheating with scope. Don't move these functions without\n",
    "# ensuring that counts will still be available\n",
    "\n",
    "def get_non_zero(condition):\n",
    "    \"\"\"Returns user ids for users who have used a targeted\n",
    "    term in their profile, and who have tweeted at least once\n",
    "    using a term which was picked up by the miner. \n",
    "    \n",
    "    NB, this does not mean that the term in the tweet(s) was\n",
    "    the same term found in their profile.\n",
    "    \n",
    "    Note that this is dependent on the particular scope\n",
    "    \"\"\"\n",
    "    return [x for x in counts[condition] if x[1] >= 1]\n",
    "\n",
    "def get_num_non_zero(condition):\n",
    "    return len(get_non_zero(condition))\n",
    "\n",
    "def get_num(condition):\n",
    "    return len(counts[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count how many users we have captured tweets for\n",
    "\n",
    "This is needed because the miner searches for users with the term in their profile and tweets. It stores them in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T21:31:24.050763Z",
     "start_time": "2018-06-05T21:31:24.043047Z"
    }
   },
   "outputs": [],
   "source": [
    "non_zero_counts = {}\n",
    "\n",
    "for condition in userIds.columns:\n",
    "    non_zero_counts[condition] = {'descripts containing term' : get_num(condition), 'users with 1+ tweets': get_num_non_zero(condition)}\n",
    "\n",
    "non_zero_counts = pd.DataFrame(non_zero_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "This means that 1439 users had the word 'arthritis' in their profile (twitter calls it a 'description'). However, we only have at least 1 tweet for 77 of the 1439. That's because the mining program's query returned both users with the term in their description and tweets containing the search term.\n",
    "\n",
    "As part of our research, we will probably want to set up a new search which pulls in tweets for a sample of the remaining users. That should be done after we figure out how to filter out some of the bots and commercial accounts.\n",
    "\n",
    "__Users with 1+ tweets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T19:39:43.888264Z",
     "start_time": "2018-06-05T19:39:43.875403Z"
    }
   },
   "outputs": [],
   "source": [
    "non_zero_counts.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T19:43:45.735647Z",
     "start_time": "2018-06-05T19:43:45.329828Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,5))\n",
    "non_zero_counts.T.plot(kind='bar', ax=axes)\n",
    "axes.set_title('Users with target terms in profile and captured terms in tweets')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Distribution of the counts__\n",
    "\n",
    "The x axis is 'Number of tweets'. Had trouble with the formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T19:46:37.338443Z",
     "start_time": "2018-06-05T19:46:36.425114Z"
    }
   },
   "outputs": [],
   "source": [
    "non_empty = []\n",
    "for cond in userIds.columns:\n",
    "    c = pd.Series([x[1] for x in get_non_zero(cond)])\n",
    "    if len(c) > 1:\n",
    "        non_empty.append((cond, c))\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(non_empty), figsize=(10,15))\n",
    "i = 0\n",
    "for cond, series in non_empty:\n",
    "#     series.plot(kind='kde', title=cond, ax=axes[i])\n",
    "    sns.violinplot(series, ax=axes[i]); axes[i].set_title(cond); #axes[i].set_x_label('# tweets')\n",
    "    i +=1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal distribution of captured tweets\n",
    "\n",
    "We should know whether the tweets containing terms of interest are evenly distributed over the capture period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T22:59:17.108014Z",
     "start_time": "2018-06-05T22:59:15.019383Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_timestamp_frame(terms):\n",
    "    \"\"\"Creates the data we need \"\"\"\n",
    "    ts = []\n",
    "    i = 1\n",
    "    for term in terms:\n",
    "        for u, c in get_non_zero(term):\n",
    "            for t in get_tweet_timestamps(u):\n",
    "                ts.append({ 'tweetTime' : pd.to_datetime(t), 'tweet': i, 'term' : term})\n",
    "        i += 1\n",
    "        print(\"%s : %s\" % (term, len(ts)))\n",
    "    ts = pd.DataFrame(ts)\n",
    "    return ts\n",
    "\n",
    "terms = [t for t in userIds.columns]\n",
    "\n",
    "# load the data\n",
    "tweet_timestamps = make_timestamp_frame(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T22:42:21.034842Z",
     "start_time": "2018-06-05T22:42:21.031374Z"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.palettes import Spectral6, Category20, magma, inferno, viridis\n",
    "\n",
    "def color_generator(num_colors, palette_function=viridis):\n",
    "    \"\"\"Returns a color from the relevant palette\"\"\"\n",
    "    colorlist = palette_function(num_colors)\n",
    "    for c in colorlist:\n",
    "        yield c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T22:18:00.418345Z",
     "start_time": "2018-06-05T22:18:00.412954Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Make a dictionary to hardcode in ticker\n",
    "dd = {}\n",
    "for i in range(1, len(userIds.columns) +1):\n",
    "    dd[i] = userIds.columns[i-1]\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T22:30:26.533115Z",
     "start_time": "2018-06-05T22:30:26.528347Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def ticker():\n",
    "    \"\"\"Replaces the numeric y axis label with the correct term\n",
    "    The dict seems to need to be hardcoded since bokeh\n",
    "    messes with any args or values which seem like they should be \n",
    "    in scope\"\"\"\n",
    "    dd = {\n",
    "        1: 'crps',\n",
    "        2: 'migraine',\n",
    "        3: 'fibromyalgia',\n",
    "        4: 'spoonie',\n",
    "        5: 'vulvodynia',\n",
    "        6: 'endometriosis',\n",
    "        7: 'neuropathy',\n",
    "        8: 'arthritis',\n",
    "        9: 'rhem_arthritis',\n",
    "        10: 'shingles',\n",
    "        11: 'backpain',\n",
    "        12: 'headache'\n",
    "    }\n",
    "\n",
    "    term = dd.get( tick )\n",
    "    return \"{}\".format( term )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the tweet distributions for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T22:58:27.295052Z",
     "start_time": "2018-06-05T22:58:27.288102Z"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.io import show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.sampledata.commits import data\n",
    "from bokeh.transform import jitter\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from bokeh.models import FuncTickFormatter\n",
    "from bokeh.models.tickers import FixedTicker\n",
    "\n",
    "\n",
    "def plot_tweet_distributions(frame, terms, title='tweet frequencies'):\n",
    "    colorgen = color_generator(len(terms))\n",
    "\n",
    "    # initialize the notebook output\n",
    "    output_notebook()\n",
    "\n",
    "    # create a new plot with a title and axis labels\n",
    "    p = figure(title=title, \n",
    "               x_axis_type=\"datetime\", \n",
    "               plot_width=800, \n",
    "               plot_height=500, \n",
    "               x_axis_label='timestamp', \n",
    "               y_axis_label='term')\n",
    "\n",
    "\n",
    "    for term in terms.columns:\n",
    "        color = next(colorgen)\n",
    "        source = ColumnDataSource(frame[frame.term == term])\n",
    "        p.circle(x='tweetTime', \n",
    "                 y=jitter('tweet', width=0.5, range=p.y_range), \n",
    "                 fill_color=color, \n",
    "                 source=source, \n",
    "                 alpha=0.6\n",
    "                )\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "    p.ygrid.grid_line_color = None\n",
    "    # p.legend.orientation = \"horizontal\"\n",
    "\n",
    "    # limit the displayed tick locations to those corresponding to the \n",
    "    # terms in the dataframe \n",
    "    tick_locations = [x for x in range(1, len(terms) + 1)]\n",
    "    p.yaxis.ticker = FixedTicker(ticks=tick_locations)\n",
    "\n",
    "    # Now add the labels instead of the numbers to the y axis\n",
    "    p.yaxis.formatter = FuncTickFormatter.from_py_func(ticker)\n",
    "\n",
    "    # show the results\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T22:59:24.345320Z",
     "start_time": "2018-06-05T22:59:23.817060Z"
    }
   },
   "outputs": [],
   "source": [
    "terms = userIds.columns\n",
    "plot_tweet_distributions(tweet_timestamps, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
