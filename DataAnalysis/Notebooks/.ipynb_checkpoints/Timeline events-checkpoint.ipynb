{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for looking at changes in tweets depending on news or other events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential timeline events\n",
    "\n",
    "Hi Adam! Just a quick glance at what google has to say:\n",
    "\n",
    "Timeline of Selected FDA Activities and Significant Events Addressing Opioid Misuse and Abuse\n",
    "\n",
    "https://www.fda.gov/Drugs/DrugSafety/InformationbyDrugClass/ucm338566.htm\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "https://www.cnn.com/2017/09/18/health/opioid-crisis-fast-facts/index.html\n",
    "\n",
    "May 20, 2015 - The DEA announces that it has arrested 280 people, including 22 doctors and pharmacists, after a 15-month sting operation centered on health care providers who dispense large amounts of opioids. The sting, dubbed Operation Pilluted, is the largest prescription drug bust in the history of the DEA.\n",
    "\n",
    "March 18, 2016 - The CDC publishes guidelines for prescribing opioids for patients with chronic pain. Recommendations include prescribing over-the-counter pain relievers like acetaminophen and ibuprofen in lieu of opioids. Doctors are encouraged to promote exercise and behavioral treatments to help patients cope with pain.\n",
    "\n",
    "March 29, 2017 - President Donald Trump signs an executive order calling for the establishment of the President's Commission on Combating Drug Addiction and the Opioid Crisis. New Jersey Governor Chris Christie is selected as the chairman of the group, with Trump's son-in-law, Jared Kushner, as an adviser.\n",
    "\n",
    "July 31, 2017 - After a delay, the White House panel examining the nation's opioid epidemic releases its interim report, asking President Trump to declare a national public health emergency to combat the ongoing crisis.\n",
    "\n",
    "August 8, 2017 - Trump holds a press briefing on opioids at his New Jersey golf club and says that a stronger law enforcement response is needed to combat the crisis. He stops short of declaring a national public health emergency.\n",
    "\n",
    "August 10, 2017 - The White House issues a press release stating that Trump is directing his \"administration to use all appropriate authority to respond to the opioid emergency.\" The administration does not, however, make a formal declaration of a national public health emergency, which would free up resources and funding to help opioid addicts and jumpstart prevention programs.\n",
    "\n",
    "September 22, 2017 - The pharmacy chain CVS announces that it will implement new restrictions on filling prescriptions for opioids, dispensing a limited seven-day supply to patients who are new to pain therapy.\n",
    "\n",
    "October 26, 2017 - President Trump declares a national public health emergency to combat the opioid crisis, telling an audience in the East Room of the White House that \"we can be the generation that ends the opioid epidemic.\"\n",
    "\n",
    "February 9, 2018 - A $6 billion boost in funding for prevention and law enforcement in the fight against opioid abuse is included in the budget agreement signed by President Trump, ending an overnight government shutdown.\n",
    "\n",
    "February 27, 2018 - Attorney General Jeff Sessions announces a new opioid task force. The Prescription Interdiction & Litigation (PIL) Task Force will target opioid manufacturers and distributors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:26:16.574847Z",
     "start_time": "2019-01-11T02:26:15.419357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bookmark:twitterproject) -> /Users/adam/Dropbox/PainNarrativesLab/TwitterProject\n",
      "/Users/adam/Dropbox/PainNarrativesLab/TwitterProject\n",
      "['/Users/adam/.pyenv/versions/3.6.4/lib/python3.6/site-packages/ipykernel_launcher.py', '--config', 'data-analysis']\n",
      "Reading configuration from /Users/adam/Dropbox/PainNarrativesLab/TwitterProject/configurations/data-analysis.config.ini\n"
     ]
    }
   ],
   "source": [
    "%cd twitterproject\n",
    "## Environmental stuff\n",
    "\n",
    "# Do this\n",
    "# inject config value (on command line would've been --config=data-analysis)\n",
    "import sys\n",
    "args = ['--config', 'data-analysis']\n",
    "# args = ['--config', 'laptop-mining']\n",
    "old_sys_argv = sys.argv\n",
    "sys.argv = [old_sys_argv[0]] + args\n",
    "import environment\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plotting \n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from TwitterDatabase.Repositories import NewOrmRepositories as R\n",
    "from TwitterDatabase.DatabaseAccessObjects import DataConnections as DC\n",
    "from TwitterDatabase.Models.WordORM import Word\n",
    "from TwitterDatabase.Models.TweetORM import Users as User\n",
    "from TwitterDatabase.Models.TweetORM import Tweet\n",
    "from DataAnalysis.SearchTools.WordMaps import get_tweet_ids_for_word, get_user_ids_for_word\n",
    "\n",
    "# EXP_TERMS_FILEPATH = '%s/experimental-terms.xlsx' % environment.EXPERIMENTS_FOLDER\n",
    "# IDS_FILEPATH = \"%s/temp_output/tweet-ids.csv\" % environment.LOG_FOLDER_PATH\n",
    "\n",
    "# def make_term_ids_filepath(term, path=environment.LOG_FOLDER_PATH):\n",
    "#     return \"%s/temp_output/tweet-ids/%s-ids.csv\" % (path, term)\n",
    "\n",
    "\n",
    "# load in terms to search for\n",
    "# experimentalTerms = pd.read_excel(environment.EXP_TERMS_FILEPATH, sheet_name='terms', squeeze=True)\n",
    "# termMap = pd.read_excel(environment.EXP_TERMS_FILEPATH, sheet_name='mapping')\n",
    "\n",
    "# terms = [t for t in termMap.T.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T01:39:25.815908Z",
     "start_time": "2019-01-11T01:39:25.724773Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:26:36.639995Z",
     "start_time": "2019-01-11T02:26:36.636911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grab all tweets for a term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:26:51.364839Z",
     "start_time": "2019-01-11T02:26:37.137166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11942"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = get_tweet_ids_for_word('dog')\n",
    "ids = [a[0] for a in r]\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T01:49:38.578342Z",
     "start_time": "2019-01-11T01:49:38.575229Z"
    }
   },
   "outputs": [],
   "source": [
    "j = ids[:4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab timestamps of those tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:29:17.983231Z",
     "start_time": "2019-01-11T02:29:17.975483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql+mysqlconnector://hobbes:taco-sauce@localhost/twitter_data?charset=utf8mb4\n"
     ]
    }
   ],
   "source": [
    "# todo This doesn't seem to be using the new credential system. Need to figure that out...\n",
    "\n",
    "conn = DC.MySqlConnection(environment.CREDENTIAL_FILE)\n",
    "dao = DC.DAO(conn.engine)\n",
    "\n",
    "errors=[]\n",
    "def get_tweet_timestamp(tweetId, errors=errors):\n",
    "    \"\"\"Returns the `created_at` field` for the indicated tweet \"\"\"\n",
    "#     try:\n",
    "    t = dao.session.query(Tweet).filter(Tweet.tweetID == tweetId).first()\n",
    "    return t.created_at\n",
    "#     except:\n",
    "#         errors.append(tweetId)\n",
    "#         print(\"Error retrieving tweet for id: {}\".format(tweetId))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:29:32.992343Z",
     "start_time": "2019-01-11T02:29:18.470218Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamps = [get_tweet_timestamp(tid) for tid in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:29:34.299559Z",
     "start_time": "2019-01-11T02:29:34.295124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11942"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:29:36.604027Z",
     "start_time": "2019-01-11T02:29:36.599225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11942"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T01:53:48.842841Z",
     "start_time": "2019-01-11T01:53:48.838483Z"
    }
   },
   "outputs": [],
   "source": [
    "timestamps[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:22:59.161039Z",
     "start_time": "2019-01-11T02:22:58.416355Z"
    }
   },
   "outputs": [],
   "source": [
    "term = 'dog'\n",
    "ts = [{ 'tweetTime' : pd.Timestamp(t), 'tweet' : 1} for t in timestamps]\n",
    "# ts = [{ 'tweetTime' : pd.to_datetime(t), 'tweet' : 1, 'term': term} for t in timestamps]\n",
    "ts = pd.DataFrame(ts)\n",
    "ts1 = ts.set_index('tweetTime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:18:23.034765Z",
     "start_time": "2019-01-11T02:18:23.025057Z"
    }
   },
   "outputs": [],
   "source": [
    "ts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:24:52.947832Z",
     "start_time": "2019-01-11T02:24:52.516035Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,4))\n",
    "ts1.resample('D').sum().plot(color='red', label='# / day', ax=axes)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:23:00.867899Z",
     "start_time": "2019-01-11T02:23:00.555040Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,4))\n",
    "ts1.plot(marker='o', linestyle='None', ax=axes)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:23:00.991914Z",
     "start_time": "2019-01-11T02:23:00.989428Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:23:01.205060Z",
     "start_time": "2019-01-11T02:23:01.194866Z"
    }
   },
   "outputs": [],
   "source": [
    "# From user categorization notebook\n",
    "\n",
    "from bokeh.io import show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.sampledata.commits import data\n",
    "from bokeh.transform import jitter\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from bokeh.models import FuncTickFormatter\n",
    "from bokeh.models.tickers import FixedTicker\n",
    "\n",
    "from bokeh.palettes import Spectral6, Category20, magma, inferno, viridis\n",
    "\n",
    "def color_generator(num_colors, palette_function=viridis):\n",
    "    \"\"\"Returns a color from the relevant palette\"\"\"\n",
    "    colorlist = palette_function(num_colors)\n",
    "    for c in colorlist:\n",
    "        yield c\n",
    "\n",
    "def plot_tweet_distributions(frame, terms, title='tweet frequencies'):\n",
    "    colorgen = color_generator(len(terms))\n",
    "\n",
    "    # initialize the notebook output\n",
    "    output_notebook()\n",
    "\n",
    "    # create a new plot with a title and axis labels\n",
    "    p = figure(title=title, \n",
    "               x_axis_type=\"datetime\", \n",
    "               plot_width=800, \n",
    "               plot_height=500, \n",
    "               x_axis_label='timestamp', \n",
    "               y_axis_label='term')\n",
    "\n",
    "\n",
    "#     for term in terms:\n",
    "    color = next(colorgen)\n",
    "    source = ColumnDataSource(frame)\n",
    "#         source = ColumnDataSource(frame[frame.term == term])\n",
    "    p.circle(x='tweetTime', \n",
    "             y=jitter('tweet', width=0.5, range=p.y_range), \n",
    "             fill_color=color, \n",
    "             source=source, \n",
    "             alpha=0.6\n",
    "            )\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "#     p.ygrid.grid_line_color = None\n",
    "    # p.legend.orientation = \"horizontal\"\n",
    "\n",
    "    # limit the displayed tick locations to those corresponding to the \n",
    "    # terms in the dataframe \n",
    "    tick_locations = [x for x in range(1, len(terms) + 1)]\n",
    "#     p.yaxis.ticker = FixedTicker(ticks=tick_locations)\n",
    "\n",
    "    # Now add the labels instead of the numbers to the y axis\n",
    "#     p.yaxis.formatter = FuncTickFormatter.from_py_func(ticker)\n",
    "\n",
    "    # show the results\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T02:23:02.994239Z",
     "start_time": "2019-01-11T02:23:02.838409Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tweet_distributions(ts, ['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
